<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-B1W20D58W2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-B1W20D58W2');
  </script>
  <title>Jinwei Xing</title>
  
  <meta name="author" content="Jinwei Xing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ‘‚</text></svg>">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jinwei Xing</name>
              </p>
              <p>
                I'm last-year PhD student at University of California, Irvine, working on Brain-Inspired Artificial Intelligence with Prof. <a href="http://www.socsci.uci.edu/~jkrichma/">Jeff Krichmar </a> and Prof. <a href="http://nmi-lab.org/authors/eneftci/"> Emre Neftci</a>. Before that, I received the B.S. degree in Computer Science from Sichuan University. 
              </p>
              <p>
                I was fortunate to work at <a href="https://cloud.google.com/products/ai">Google Cloud AI</a> as a software engineer intern and research scientist intern at <a href="https://www.amazon.science/tag/supply-chain-optimization-technologies">Amazon</a>. I'm interested in applying machine learning in real-world scenarios and have experience in reinforcement learning, computer vision, natural language processing, recommender systems, mobile robotics and neuromorphic computing.
              </p>
              <p style="text-align:center">
                <a href="mailto:jinweixing1006@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=agANVQoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/karlxing/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jinwei-xing-a3b827118"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:35%;max-width:40%">
              <a href="images/me.png"><img style="width:100%;max-width:90%" alt="profile photo" src="images/me.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>	
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/digr.gif" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Policy Distillation with Selective Input Gradient Regularization for Efficient Interpretability</papertitle>
              </a>
              <br>               <br>
              <strong>Jinwei Xing</strong>, Takashi Nagata, Xinyun Zou, Emre Neftci, Jeffrey L. Krichmar
              <br>
							<em>Neural Networks, 2023</em> 
              <br>
              <p></p>
              <p>Conducting input gradient regularization along with policy distillation allows us to generate highly interpretable gradient-based saliency maps and produce more robust policies. </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/pnas.png" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.pnas.org/doi/10.1073/pnas.2202024119">
                <papertitle>Linking global top-down views to first-person views in the brain</papertitle>
              </a>
              <br>               <br>
              <strong>Jinwei Xing</strong>, Elizabeth R. Chrastil, Douglas A. Nitz, Jeffrey L. Krichmar
              <br>
							<em>PNAS, 2022</em>
              <br>
              <p></p>
              <p> To investigate the underlying computations needed to implement the important cognitive function of linking between a first-person experience and a global map in our brain, we used variational autoencoders to reconstruct the top-down images from a robotâ€™s camera view, and vice versa, and conducted analysis. </p>
            </td>
          </tr> 


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/lusr.gif" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2102.05714">
                <papertitle>Domain Adaptation In Reinforcement Learning Via Latent Unified State Representation</papertitle>
              </a>
              <br>               <br>

              <strong>Jinwei Xing</strong>, Takashi Nagata, Kexin Chen, Xinyun Zou, Emre Neftci, Jeffrey L. Krichmar
              <br>
              <em>AAAI</em>, 2021 &nbsp <a href="https://github.com/KarlXing/LUSR">[code]</a>
              <br>              
              <p></p>
              <p>By separating domain-general and domain-specifc information and conduct RL training based on domain-general embedding, RL policies could achieve almost zero performance loss when depolyed in new domains.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/neurorobot.jpg" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2020.570308/full">
                <papertitle>Neurorobots as a Means Toward Neuroethology and Explainable AI</papertitle>
              </a>
              <br>               <br>
              Stewart, Kenneth, Kexin Chen, Tiffany Hwu, Hirak J. Kashyap, Jeffrey L. Krichmar, <strong>Jinwei Xing</strong>, and Xinyun Zou
              <br>
              <em>Frontiers in Neurorobotics</em>, 2020 &nbsp
              <br>              
              <p></p>
              <p>Using neurorobots as a form of computational neuroethology can be a powerful methodology for understanding neuroscience, as well as for artificial intelligence and machine learning.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/roadfollow.gif" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9206642">
                <papertitle>Neuromodulated Patience for Robot and Self-Driving Vehicle Navigation</papertitle>
              </a>
              <br>               <br>
              <strong>Jinwei Xing</strong>, Xinyun Zou, Jeffrey L Krichmar
              <br>
              <em>IJCNN</em>, 2020 &nbsp
              <br>              
              <p></p>
              <p>Using semantic segmentation and deep Q learning to train a mobile robot that can drive in wilder environments.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/carlsim4.png" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.socsci.uci.edu/~jkrichma/Chou-Kashyap-CARLsim4-IJCNN2018.pdf">
                <papertitle>CARLsim 4: an open source library for large scale, biologically detailed spiking neural network simulation using heterogeneous clusters</papertitle>
              </a>
              <br>               <br>
              Ting-Shuo Chou, Hirak J Kashyap, <strong>Jinwei Xing</strong> , Stanislav Listopad, Emily L Rounds, Michael Beyeler, Nikil Dutt, Jeffrey L Krichmar
              <br>
              <em>IJCNN</em>, 2018 &nbsp
              <br>              
              <p></p>
              <p>CARLsim is an efficient, easy-to-use, GPU-accelerated library for simulating large-scale spiking neural network (SNN) models with a high degree of biological detail.</p>
            </td>
          </tr>
          
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Other Projects</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/rlrl.png" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/KarlXing/RL-Visual-Continuous-Control">
                <papertitle>Reinforcement Learning Algorithms for Visual Continuous Control</papertitle>
              </a>
              <br>               <br>
              <a href="https://github.com/KarlXing/RL-Visual-Continuous-Control">[code]</a>
              <br>              
              <p></p>
              <p>This project provides a modularized and unified implementation of a series of visual/image-based reinforcement learning algorithms (e.g. SAC, SAC+AE, CURL, RAD, DrQ and ATC) for continuous control tasks.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry'><img src="images/rlcodebase.png" width="200"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/KarlXing/RLCodebase">
                <papertitle>RLCodebase: PyTorch Codebase For Deep Reinforcement Learning Algorithms</papertitle>
              </a>
              <br>               <br>
              <a href="https://github.com/KarlXing/RLCodebase">[code]</a>
              <br>              
              <p></p>
              <p>RLCodebase is a modularized codebase for deep reinforcement learning algorithms based on PyTorch. This project aims to provide an user-friendly reinforcement learning codebase for beginners to get started and for researchers to try their ideas quickly and efficiently.</p>
            </td>
          </tr>
        </tbody></table>


      </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
